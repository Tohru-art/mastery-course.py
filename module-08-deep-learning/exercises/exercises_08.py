"""
MODULE 8 EXERCISES — Deep Learning & LLMs
===========================================
Run: python exercises/exercises_08.py
"""
import numpy as np


# ══════════════════════════════════════════════════════
# EXERCISE 1: Activation Functions
# ══════════════════════════════════════════════════════
def sigmoid(x: np.ndarray) -> np.ndarray:
    """Sigmoid activation: 1 / (1 + e^-x)"""
    pass  # YOUR CODE HERE

def relu(x: np.ndarray) -> np.ndarray:
    """ReLU: max(0, x)"""
    pass  # YOUR CODE HERE

def softmax(x: np.ndarray) -> np.ndarray:
    """Softmax for multi-class: e^x / sum(e^x). Numerically stable version."""
    pass  # YOUR CODE HERE


# ══════════════════════════════════════════════════════
# EXERCISE 2: Loss Functions
# ══════════════════════════════════════════════════════
def binary_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    BCE = -mean(y * log(y_pred) + (1-y) * log(1-y_pred))
    Clip y_pred to [1e-7, 1-1e-7] to avoid log(0).
    """
    pass  # YOUR CODE HERE

def mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """MSE = mean((y_true - y_pred)^2)"""
    pass  # YOUR CODE HERE


# ══════════════════════════════════════════════════════
# EXERCISE 3: Evaluate AI-Generated Code
# ══════════════════════════════════════════════════════
"""
The following training loop was generated by an AI assistant.
Find ALL the bugs and list them.
Then implement a fixed version.
"""

def buggy_training_loop_reference():
    """
    Reference (DON'T run this — it has bugs):

    model.train()
    for X_batch, y_batch in train_loader:
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        loss.backward()
        # Missing: optimizer.zero_grad() before backward!
        optimizer.step()
        # Missing: model.eval() and torch.no_grad() for validation
    accuracy = model.score(X_train, y_train)  # evaluating on TRAIN data!
    """
    pass

def list_training_loop_bugs() -> list:
    """
    Return a list of strings describing each bug in buggy_training_loop_reference.
    Expected: at least 3 bugs.
    """
    # YOUR CODE HERE
    pass


# ══════════════════════════════════════════════════════
# EXERCISE 4: Prompt Templates
# ══════════════════════════════════════════════════════
def build_classification_prompt(text: str, categories: list) -> str:
    """
    Build a prompt that asks an LLM to classify 'text' into one of 'categories'.
    The prompt must:
    1. Include a system role instruction
    2. List the valid categories clearly
    3. Ask the LLM to return ONLY JSON: {"category": "...", "confidence": 0.0-1.0}
    4. Include the text to classify

    Example:
        build_classification_prompt("Python is great", ["positive", "negative"])
        → a prompt string that would make an LLM classify the sentiment
    """
    # YOUR CODE HERE
    pass


def extract_json_from_response(response: str) -> dict:
    """
    Extract and parse JSON from an LLM response.
    The response might have text before/after the JSON.
    Return the parsed dict, or {"error": "no json found"} if parsing fails.
    Hint: use re.search with a pattern that matches {...}
    """
    import re, json
    # YOUR CODE HERE
    pass


# ══════════════════════════════════════════════════════
# TEST RUNNER
# ══════════════════════════════════════════════════════
def run_tests():
    passed = failed = 0
    def check(name, result, expected, tol=1e-4):
        nonlocal passed, failed
        if isinstance(expected, np.ndarray):
            ok = np.allclose(result, expected, atol=tol) if result is not None else False
        elif isinstance(expected, float):
            ok = abs((result or 0) - expected) < tol
        else:
            ok = result == expected
        if ok: print(f"  PASS  {name}"); passed += 1
        else:
            print(f"  FAIL  {name}")
            print(f"         Expected: {expected}, Got: {result}")
            failed += 1

    print("\n=== MODULE 8 TESTS ===\n")

    x = np.array([-2., 0., 2.])

    # Activations
    s = sigmoid(x)
    check("sigmoid(0)", s[1] if s is not None else None, 0.5)
    check("sigmoid range", all(0 < v < 1 for v in (s or [])), True)

    r = relu(x)
    check("relu(-2)", (r[0] if r is not None else None), 0.0)
    check("relu(2)", (r[2] if r is not None else None), 2.0)

    sm = softmax(np.array([1., 2., 3.]))
    check("softmax sums to 1", abs(sum(sm or [0]) - 1.0) < 1e-6, True)

    # Loss functions
    y_true = np.array([1., 0., 1.])
    y_pred = np.array([0.9, 0.1, 0.8])
    bce = binary_cross_entropy(y_true, y_pred)
    check("BCE reasonable", bce is not None and 0 < bce < 1, True)

    mse = mean_squared_error(np.array([1.,2.,3.]), np.array([1.,2.,3.]))
    check("MSE perfect", mse, 0.0)

    # Bug list
    bugs = list_training_loop_bugs()
    check("finds 3+ bugs", len(bugs or []) >= 3, True)

    # Prompt template
    prompt = build_classification_prompt("I love this!", ["positive", "negative"])
    if prompt:
        check("prompt has JSON instruction", "json" in prompt.lower(), True)
        check("prompt has categories", "positive" in prompt and "negative" in prompt, True)

    # JSON extraction
    response = 'Here is my answer: {"category": "positive", "confidence": 0.9} done.'
    extracted = extract_json_from_response(response)
    if extracted:
        check("extract category", extracted.get("category"), "positive")

    print(f"\n{'='*30}\nResults: {passed} passed, {failed} failed")
    if failed == 0: print("All tests passed! Commit your work.")

if __name__ == "__main__":
    run_tests()
